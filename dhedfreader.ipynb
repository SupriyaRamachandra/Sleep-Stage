{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, datetime, operator, logging\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "EVENT_CHANNEL = 'EDF Annotations'\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDFEndOfData: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tal(tal_str):\n",
    "    exp = '(?P<onset>[+\\-]\\d+(?:\\.\\d*)?)' + \\\n",
    "    '(?:\\x15(?P<duration>\\d+(?:\\.\\d*)?))?' + \\\n",
    "    '(\\x14(?P<annotation>[^\\x00]*))?' + \\\n",
    "    '(?:\\x14\\x00)'\n",
    "    def annotation_to_list(annotation):\n",
    "        #print('annotatn:',annotation)\n",
    "        return str(annotation).split('\\x14') if annotation else []\n",
    "    def parse(dic):\n",
    "        return (float(dic['onset']),float(dic['duration']) if dic['duration'] else 0.,annotation_to_list(dic['annotation']))\n",
    "    return [parse(m.groupdict()) for m in re.finditer(exp, tal_str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edf_header(f):\n",
    "    h = {}\n",
    "    assert f.tell() == 0  # check file position\n",
    "    assert f.read(8) == '0       '\n",
    "  # recording info)\n",
    "    h['local_subject_id'] = f.read(80).strip()\n",
    "    h['local_recording_id'] = f.read(80).strip()\n",
    "  # parse timestamp\n",
    "    (day, month, year) = [int(x) for x in re.findall('(\\d+)', f.read(8))]\n",
    "    (hour, minute, sec)= [int(x) for x in re.findall('(\\d+)', f.read(8))]\n",
    "    h['date_time'] = str(datetime.datetime(year + 2000, month, day,hour, minute, sec))\n",
    "  # misc\n",
    "    header_nbytes = int(f.read(8))\n",
    "    subtype = f.read(44)[:5]\n",
    "    h['EDF+'] = subtype in ['EDF+C', 'EDF+D']\n",
    "    h['contiguous'] = subtype != 'EDF+D'\n",
    "    h['n_records'] = int(f.read(8))\n",
    "    h['record_length'] = float(f.read(8))  # in seconds\n",
    "    nchannels = h['n_channels'] = int(f.read(4))\n",
    "  # read channel info\n",
    "    channels = range(h['n_channels'])\n",
    "    h['label'] = [f.read(16).strip() for n in channels]\n",
    "    h['transducer_type'] = [f.read(80).strip() for n in channels]\n",
    "    h['units'] = [f.read(8).strip() for n in channels]\n",
    "    h['physical_min'] = np.asarray([float(f.read(8)) for n in channels])\n",
    "    h['physical_max'] = np.asarray([float(f.read(8)) for n in channels])\n",
    "    h['digital_min'] = np.asarray([float(f.read(8)) for n in channels])\n",
    "    h['digital_max'] = np.asarray([float(f.read(8)) for n in channels])\n",
    "    h['prefiltering'] = [f.read(80).strip() for n in channels]\n",
    "    h['n_samples_per_record'] = [int(f.read(8)) for n in channels]\n",
    "    f.read(32 * nchannels)  # reserved\n",
    "    assert f.tell() == header_nbytes\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEDFReader:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "    def read_header(self):\n",
    "        print('read_header')\n",
    "        self.header = h = edf_header(self.file)\n",
    "        # calculate ranges for rescaling\n",
    "        self.dig_min = h['digital_min']\n",
    "        self.phys_min = h['physical_min']\n",
    "        phys_range = h['physical_max'] - h['physical_min']\n",
    "        dig_range = h['digital_max'] - h['digital_min']\n",
    "        assert np.all(phys_range > 0)\n",
    "        assert np.all(dig_range > 0)\n",
    "        self.gain = phys_range / dig_range\n",
    "    def read_raw_record(self):\n",
    "        print('read raw record')\n",
    "        #Read a record with data and return a list containing arrays with raw bytes.\n",
    "        result = []\n",
    "        for nsamp in self.header['n_samples_per_record']:\n",
    "            samples = self.file.read(nsamp * 2)\n",
    "            if len(samples) != nsamp * 2:\n",
    "                raise EDFEndOfData\n",
    "            result.append(samples)\n",
    "        return result\n",
    "    def convert_record(self, raw_record):\n",
    "        print('convert record')\n",
    "        #Convert a raw record to a (time, signals, events) tuple based on information in the header.\n",
    "        h = self.header\n",
    "        dig_min, phys_min, gain = self.dig_min, self.phys_min, self.gain\n",
    "        time = float('nan')\n",
    "        signals = []\n",
    "        events = []\n",
    "        for (i, samples) in enumerate(raw_record):\n",
    "            if h['label'][i] == EVENT_CHANNEL:\n",
    "                ann = tal(samples)\n",
    "                time = ann[0][0]\n",
    "                events.extend(ann[1:])\n",
    "        # print(i, samples)\n",
    "        # exit()\n",
    "            else:\n",
    "            # 2-byte little-endian integers\n",
    "                dig = np.fromstring(samples, '<i2').astype(np.float32)\n",
    "                phys = (dig - dig_min[i]) * gain[i] + phys_min[i]\n",
    "                signals.append(phys)\n",
    "        return time, signals, events\n",
    "    def read_record(self):\n",
    "        print('read_record')\n",
    "        return self.convert_record(self.read_raw_record())\n",
    "    def records(self):\n",
    "        print('record self')\n",
    "        #Record generator.\n",
    "        yield self.read_record()\n",
    "        \"\"\"try:\n",
    "            while True:\n",
    "                yield self.read_record()\n",
    "        except EDFEndOfData:\n",
    "            pass\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_edf(edffile):\n",
    "    \"\"\"Load an EDF+ file.\n",
    "     Very basic reader for EDF and EDF+ files. While BaseEDFReader does support\n",
    "  exotic features like non-homogeneous sample rates and loading only parts of\n",
    "  the stream, load_edf expects a single fixed sample rate for all channels and\n",
    "  tries to load the whole file.\n",
    "  Parameters\n",
    "  ----------\n",
    "  edffile : file-like object or string\n",
    "  Returns\n",
    "  -------\n",
    "  Named tuple with the fields:\n",
    "    X : NumPy array with shape p by n.\n",
    "      Raw recording of n samples in p dimensions.\n",
    "    sample_rate : float\n",
    "      The sample rate of the recording. Note that mixed sample-rates are not\n",
    "      supported.\n",
    "    sens_lab : list of length p with strings\n",
    "      The labels of the sensors used to record X.\n",
    "    time : NumPy array with length n\n",
    "      The time offset in the recording for each sample.\n",
    "    annotations : a list with tuples      EDF+ annotations are stored in (start, duration, description) tuples.\n",
    "      start : float\n",
    "        Indicates the start of the event in seconds.\n",
    "      duration : float\n",
    "        Indicates the duration of the event in seconds.\n",
    "      description : list with strings\n",
    "        Contains (multiple?) descriptions of the annotation event.\"\"\"\n",
    "    if isinstance(edffile, basestring):\n",
    "        with open(edffile, 'rb') as f:\n",
    "            return load_edf(f)  # convert filename to file\n",
    "    reader = BaseEDFReader(edffile)\n",
    "    reader.read_header()\n",
    "    h = reader.header\n",
    "    log.debug('EDF header: %s' % h)\n",
    "  # get sample rate info\n",
    "    nsamp = np.unique(\n",
    "    [n for (l, n) in zip(h['label'], h['n_samples_per_record'])\n",
    "    if l != EVENT_CHANNEL])\n",
    "    assert nsamp.size == 1, 'Multiple sample rates not supported!'\n",
    "    sample_rate = float(nsamp[0]) / h['record_length']\n",
    "    rectime, X, annotations = zip(*reader.records())\n",
    "    X = np.hstack(X)\n",
    "    annotations = reduce(operator.add, annotations)\n",
    "    chan_lab = [lab for lab in reader.header['label'] if lab != EVENT_CHANNEL]\n",
    "  # create timestamps\n",
    "    if reader.header['contiguous']:\n",
    "        time = np.arange(X.shape[1]) / sample_rate\n",
    "    else:\n",
    "        reclen = reader.header['record_length']\n",
    "        within_rec_time = np.linspace(0, reclen, nsamp, endpoint=False)\n",
    "        time = np.hstack([t + within_rec_time for t in rectime])\n",
    "    tup = namedtuple('EDF', 'X sample_rate chan_lab time annotations')\n",
    "    return tup(X, sample_rate, chan_lab, time, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
